{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import glob as glob\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "plt.rcParams['figure.figsize'] = (20.0, 10.0)\n",
    "%matplotlib inline\n",
    "\n",
    "from utilities import *\n",
    "from skimage.feature import hog\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.ndimage.measurements import label\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from alexnet import AlexNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Samples  Labels  Weights\n",
      "Vehicles:      8827     8827    8827\n",
      "Non-Vehicles:  9006     9006    9006\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "nom_vehicle_filenames = glob.glob('train_images_vehicles/*/*.png')\n",
    "nom_non_vehicle_filenames = glob.glob('train_images_non_vehicles/*/*.png')\n",
    "extra_vehicle_filenames = glob.glob('train_extra/vehicles/*.jpg')\n",
    "extra_non_vehicle_filenames = glob.glob('train_extra/non_vehicles/*.jpg')\n",
    "\n",
    "vehicle_filenames=nom_vehicle_filenames+extra_vehicle_filenames\n",
    "non_vehicle_filenames=nom_non_vehicle_filenames+extra_non_vehicle_filenames\n",
    "##\n",
    "vehicle_labels = np.ones((len(vehicle_filenames)))\n",
    "non_vehicle_labels = np.zeros((len(non_vehicle_filenames)))\n",
    "##\n",
    "extra_weight = 2\n",
    "nom_vehicle_weights = np.ones((len(nom_vehicle_filenames)))\n",
    "nom_non_vehicle_weights = np.ones((len(nom_non_vehicle_filenames)))\n",
    "extra_vehicle_weights = np.ones((len(extra_vehicle_filenames)))*extra_weight\n",
    "extra_non_vehicle_weights = np.ones((len(extra_non_vehicle_filenames)))*extra_weight\n",
    "\n",
    "vehicle_weights = np.concatenate([nom_vehicle_weights, extra_vehicle_weights])\n",
    "non_vehicle_weights = np.concatenate([nom_non_vehicle_weights, extra_non_vehicle_weights])\n",
    "#sample_weights = np.concatenate([vehicle_weights, non_vehicle_weights])\n",
    "##\n",
    "print(\"               Samples  Labels  Weights\")\n",
    "print(\"Vehicles:     \", len(vehicle_filenames), \"   \", len(vehicle_labels), \"  \", len(vehicle_weights))\n",
    "print(\"Non-Vehicles: \", len(non_vehicle_filenames), \"   \", len(non_vehicle_labels), \"  \", len(non_vehicle_weights))\n",
    "#print(len(nom_non_vehicle_filenames))\n",
    "#print(len(extra_vehicle_filenames))\n",
    "#print(len(extra_non_vehicle_filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vehicle_ims = [mpimg.imread(fname) for fname in nom_vehicle_filenames]\n",
    "non_vehicle_ims = [mpimg.imread(fname) for fname in nom_non_vehicle_filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17760, 64, 64, 3) (17760,)\n"
     ]
    }
   ],
   "source": [
    "X_all = np.array(vehicle_ims+non_vehicle_ims)\n",
    "\n",
    "vehicle_labels = np.ones((len(vehicle_ims)))\n",
    "non_vehicle_labels = np.zeros((len(non_vehicle_ims)))\n",
    "y_all = np.concatenate([vehicle_labels, non_vehicle_labels])\n",
    "\n",
    "print(X_all.shape, y_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = vehicle_filenames[5]\n",
    "im=mpimg.imread(fname)\n",
    "showImage(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# utility functions\n",
    "\n",
    "def getHOGFeatures(img, orient, pix_per_cell, cell_per_block, vis=False, feature_vec=True):\n",
    "  # img: must be greyscale\n",
    "  # orient: number of orientation bins\n",
    "  # \n",
    "  if vis == True:\n",
    "    features, hog_image = hog(img, \n",
    "                              orientations=orient, \n",
    "                              pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                              cells_per_block=(cell_per_block, cell_per_block), \n",
    "                              transform_sqrt=False,\n",
    "                              visualise=True, \n",
    "                              feature_vector=False,\n",
    "                              block_norm='L1')\n",
    "    return features, hog_image\n",
    "  else:      \n",
    "    features = hog(img, \n",
    "                   orientations=orient, \n",
    "                   pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                   cells_per_block=(cell_per_block, cell_per_block), \n",
    "                   transform_sqrt=False, \n",
    "                   visualise=False, \n",
    "                   feature_vector=feature_vec,\n",
    "                   block_norm='L1')\n",
    "    return features\n",
    "  \n",
    "def getColorHistogram(imgs, nbins=32, channels=[], bins_range=[0, 256]):\n",
    "  # we use opencv's histogram calculator bc it is ~40x faster (according to opencv's tutorial)\n",
    "  # imgs, channels, histSize, ranges must be lists i.e. [...]\n",
    "  tbr = []\n",
    "  for c in channels:\n",
    "    hist = cv2.calcHist(images = imgs,channels=[c],mask=None,histSize=nbins,ranges=bins_range)\n",
    "    tbr.append(hist)\n",
    "  return np.reshape(np.concatenate(tbr), (-1))\n",
    "\n",
    "def customFilter(img):\n",
    "  fac1 = 0.01 # Cutoff\n",
    "  fac2 = 0.04 # Steepness\n",
    "  Z = 255.0 / (1.0+fac1*np.exp(fac2*((255.0-img[:, :, 0]) + (255.0-img[:, :, 1])))) \n",
    "  return Z.astype(np.uint8)\n",
    "\n",
    "def spatialBinning(img, color_space='RGB', size=(32, 32)):\n",
    "  # img: should be RGB if color_space is not RGB\n",
    "  # Convert image to new color space if specified\n",
    "  if color_space != 'RGB':\n",
    "    if color_space == 'HSV':\n",
    "      feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "    elif color_space == 'LUV':\n",
    "      feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2LUV)\n",
    "    elif color_space == 'HLS':\n",
    "      feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    elif color_space == 'YUV':\n",
    "      feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2YUV)\n",
    "    elif color_space == 'YCrCb':\n",
    "      feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2YCrCb)\n",
    "    elif color_space == 'GRY':\n",
    "      feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    elif color_space == 'CST':\n",
    "      feature_image = customFilter(img)\n",
    "  else: feature_image = np.copy(img)             \n",
    "  # Use cv2.resize().ravel() to create the feature vector\n",
    "  features = cv2.resize(feature_image, size).ravel() \n",
    "  # Return the feature vector\n",
    "  return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imagePipeline(img, print_stats=False, scaler=None):\n",
    "  \n",
    "  do_hog = True\n",
    "  do_color_hist = False\n",
    "  do_spatial = False\n",
    "  \n",
    "  features = []\n",
    "  \n",
    "  if do_hog == True:\n",
    "    g_im = greyscale(img)\n",
    "    num_orient_bins = 9\n",
    "    pix_per_cell = 6\n",
    "    cell_per_block = 2\n",
    "    hog_features = getHOGFeatures(img=g_im, \n",
    "                                  orient=num_orient_bins, \n",
    "                                  pix_per_cell=pix_per_cell, \n",
    "                                  cell_per_block=cell_per_block, \n",
    "                                  vis=False, \n",
    "                                  feature_vec=True)\n",
    "    if print_stats == True:\n",
    "      print('hog: ', hog_features.shape)\n",
    "      print('  mean: ', np.mean(hog_features))\n",
    "      print('  std: ', np.std(hog_features))\n",
    "      print('  min, max: ', np.min(hog_features), np.max(hog_features))\n",
    "    features.append(hog_features)\n",
    "    \n",
    "  if do_color_hist == True:\n",
    "    nbins = [32]\n",
    "    channels = [0, 1, 2]\n",
    "    b_range = [0, 256]\n",
    "    hist_features = getColorHistogram(imgs=[img], \n",
    "                                      nbins=nbins, \n",
    "                                      channels=channels, \n",
    "                                      bins_range=b_range)\n",
    "    if print_stats == True:\n",
    "      print('color histogram: ', hist_features.shape)\n",
    "      print('  mean: ', np.mean(hist_features))\n",
    "      print('  std: ', np.std(hist_features))\n",
    "      print('  min, max: ', np.min(hist_features), np.max(hist_features))\n",
    "    features.append(hist_features)\n",
    "\n",
    "  if do_spatial == True:\n",
    "    new_size = (32, 32)\n",
    "    c_space = 'YCrCb'\n",
    "    bin_features = spatialBinning(img=img, \n",
    "                                  color_space=c_space,\n",
    "                                  size=new_size)\n",
    "    if print_stats == True:\n",
    "      print('spatial binning (image resizing): ', bin_features.shape)\n",
    "      print('  mean: ', np.mean(bin_features))\n",
    "      print('  std: ', np.std(bin_features))\n",
    "      print('  min, max: ', np.min(bin_features), np.max(bin_features))\n",
    "    features.append(bin_features)\n",
    "  \n",
    "  tbr = np.concatenate(features)\n",
    "  if scaler is not None:\n",
    "    tbr = scaler.transform(tbr.reshape(1, -1))\n",
    "  return tbr\n",
    "\n",
    "# Generate a random index to look at a car image\n",
    "ind = np.random.randint(0, len(vehicle_filenames))\n",
    "# Read in the image\n",
    "im, im_shape = loadImage(vehicle_filenames[ind], greyscale=False)\n",
    "\n",
    "print(im_shape)\n",
    "test_f = imagePipeline(im, print_stats=True)\n",
    "print(test_f.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from random import randint\n",
    "\n",
    "def augmentSingleImage(img, num_perturbs=0):\n",
    "    # Flip all images horizontally\n",
    "    xtended = np.array([img, img[ :, ::-1, :]])\n",
    "    # perturb flipped images\n",
    "    xtended_len = xtended.shape[0]\n",
    "    for i in range(0, num_perturbs):\n",
    "        pert_ims = np.array([perturb(img_t) for img_t in xtended[:xtended_len, :, :, :]])\n",
    "        xtended = np.append(xtended, pert_ims, axis=0)\n",
    "\n",
    "    return xtended\n",
    "\n",
    "def extractFeatures(filenames, show_summary=False):\n",
    "  f_list = []\n",
    "  for fname in filenames:\n",
    "    img = mpimg.imread(fname)\n",
    "    #imgs = augmentSingleImage(img, num_perturbs=1)\n",
    "    #for i in imgs:\n",
    "    #  features = imagePipeline(img)\n",
    "    #  f_list.append(features)\n",
    "    features = imagePipeline(img)\n",
    "    f_list.append(features)\n",
    "    \n",
    "  return np.array(f_list)\n",
    "\n",
    "t1 = time.time()\n",
    "vehicle_features = extractFeatures(vehicle_filenames)\n",
    "non_vehicle_features = extractFeatures(non_vehicle_filenames)\n",
    "time_taken = time.time() - t1\n",
    "print(\"Time to extract Features: \", time_taken)\n",
    "print(\"Vehicles: \", vehicle_features.shape[0])\n",
    "print(\"Non-Vehicles: \", non_vehicle_features.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def insert_subimage(image, sub_image, y, x): \n",
    "    h, w, c = sub_image.shape\n",
    "    image[y:y+h, x:x+w, :]=sub_image \n",
    "    return image\n",
    "\n",
    "def showSampleImage(im_list):\n",
    "  im_height, im_width, im_chan = (64, 64, 3)\n",
    "  num_rows = 10\n",
    "  num_cols = 10\n",
    "  results_image = 255.*np.ones(shape=(num_rows*im_height, num_cols*im_width, im_chan),dtype=np.float32)\n",
    "  sample_ims=10\n",
    "  for r in range(num_rows):\n",
    "    for c in range(num_cols):\n",
    "      im = mpimg.imread(im_list[randint(0, len(im_list))])\n",
    "      insert_subimage(results_image, im, r*im_height, c*im_width)\n",
    "  return results_image\n",
    "\n",
    "f_num = 0\n",
    "v_sample = showSampleImage(vehicle_filenames)\n",
    "plt.rcParams[\"figure.figsize\"] = (25,25)\n",
    "f_num = showImage(v_sample, f_num)\n",
    "nv_sample = showSampleImage(non_vehicle_filenames)\n",
    "plt.rcParams[\"figure.figsize\"] = (25,25)\n",
    "f_num = showImage(nv_sample, f_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_weights = np.concatenate([vehicle_weights, non_vehicle_weights])\n",
    "all_features = np.concatenate([vehicle_features, non_vehicle_features])\n",
    "all_labels = np.concatenate([vehicle_labels, non_vehicle_labels])\n",
    "\n",
    "print(all_labels.shape)\n",
    "y_data = np.concatenate([all_labels, all_weights])\n",
    "print(y_data.shape)\n",
    "\n",
    "X_scaler = StandardScaler().fit(X_data)\n",
    "scaled_X = X_scaler.transform(X_data)\n",
    "\n",
    "#X_train, X_val, y_train, y_val = train_test_split(scaled_X, y_data, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Validation Accuracy: \n",
      "0.628941441441"
     ]
    }
   ],
   "source": [
    "nb_classes = 2\n",
    "epochs = 10\n",
    "batch_size = 128\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_all, y_all, test_size=0.2, random_state=0)\n",
    "\n",
    "features = tf.placeholder(tf.float32, (None, 64, 64, 3))\n",
    "labels = tf.placeholder(tf.int64, None)\n",
    "resized = tf.image.resize_images(features, (227, 227))\n",
    "\n",
    "# Returns the second final layer of the AlexNet model,\n",
    "# this allows us to redo the last layer for the traffic signs\n",
    "# model.\n",
    "fc7 = AlexNet(resized, feature_extract=True)\n",
    "fc7 = tf.stop_gradient(fc7)\n",
    "shape = (fc7.get_shape().as_list()[-1], nb_classes)\n",
    "fc8W = tf.Variable(tf.truncated_normal(shape, stddev=1e-2))\n",
    "fc8b = tf.Variable(tf.zeros(nb_classes))\n",
    "logits = tf.nn.xw_plus_b(fc7, fc8W, fc8b)\n",
    "\n",
    "cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=labels)\n",
    "loss_op = tf.reduce_mean(cross_entropy)\n",
    "opt = tf.train.AdamOptimizer()\n",
    "train_op = opt.minimize(loss_op, var_list=[fc8W, fc8b])\n",
    "init_op = tf.global_variables_initializer()\n",
    "\n",
    "preds = tf.arg_max(logits, 1)\n",
    "accuracy_op = tf.reduce_mean(tf.cast(tf.equal(preds, labels), tf.float32))\n",
    "\n",
    "\n",
    "def eval_on_data(X, y, sess):\n",
    "    total_acc = 0\n",
    "    total_loss = 0\n",
    "    for offset in range(0, X.shape[0], batch_size):\n",
    "        end = offset + batch_size\n",
    "        X_batch = X[offset:end]\n",
    "        y_batch = y[offset:end]\n",
    "\n",
    "        loss, acc = sess.run([loss_op, accuracy_op], feed_dict={features: X_batch, labels: y_batch})\n",
    "        total_loss += (loss * X_batch.shape[0])\n",
    "        total_acc += (acc * X_batch.shape[0])\n",
    "\n",
    "    return total_loss/X.shape[0], total_acc/X.shape[0]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "  sess.run(init_op)\n",
    "  for i in range(epochs):\n",
    "    # training\n",
    "    print(\"Epoch\", i+1)\n",
    "    t0 = time.time()\n",
    "    X_train, y_train = shuffle(X_train, y_train)\n",
    "    for offset in range(0, X_train.shape[0], batch_size):\n",
    "      end = offset + batch_size\n",
    "      sess.run(train_op, feed_dict={features: X_train[offset:end], labels: y_train[offset:end]})\n",
    "      val_loss, val_acc = eval_on_data(X_val, y_val, sess)\n",
    "      print(\"Validation Accuracy: \")\n",
    "      print(val_acc, sep=' ', end='', flush=True)\n",
    "    val_loss, val_acc = eval_on_data(X_val, y_val, sess)\n",
    "    print(\"  Time: %.3f seconds\" % (time.time() - t0))\n",
    "    print(\"  Validation Loss =\", val_loss)\n",
    "    print(\"  Validation Accuracy =\", val_acc)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use a linear SVC \n",
    "clf = 'SVC'\n",
    "svc = SVC(kernel='linear', probability=False)\n",
    "# scores = svc.decision_function(X)\n",
    "\n",
    "## Use a Decision Tree\n",
    "#clf = 'DT'\n",
    "#svc = DecisionTreeClassifier(min_samples_split=50)\n",
    "#scores = svc.predict_proba(X)\n",
    "\n",
    "# Check the training time for the SVC\n",
    "t1=time.time()\n",
    "svc.fit(X_train, y_train, sample_weights)\n",
    "t2 = time.time()\n",
    "training_time = round(t2-t1, 4)\n",
    "print(training_time, 'Seconds to train SVC...')\n",
    "# Check the score of the SVC\n",
    "svc_score = round(svc.score(X_test, y_test), 8)\n",
    "print('Test Accuracy of SVC = ', svc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "im_shape = (720, 1280)\n",
    "near_min_row = im_shape[0]-40\n",
    "far_min_row = 460\n",
    "\n",
    "near_max_height = 290\n",
    "far_max_height = 80\n",
    "\n",
    "near_width = 300\n",
    "far_width = 70\n",
    "\n",
    "near_step_size = 30\n",
    "far_step_size = 10\n",
    "\n",
    "sampling_num = 30\n",
    "base = 5\n",
    "\n",
    "min_row_sampling=np.logspace(start=math.log(near_min_row, base), stop=math.log(far_min_row, base), num=sampling_num, base=base, dtype=np.uint16)\n",
    "print(min_row_sampling)\n",
    "max_height_sampling=np.logspace(start=math.log(near_max_height, base), stop=math.log(far_max_height, base), num=sampling_num, base=base, dtype=np.uint16)\n",
    "#width_sampling=np.logspace(start=math.log(near_width, base), stop=math.log(far_width, base), num=sampling_num, base=base, dtype=np.uint16)\n",
    "width_sampling=max_height_sampling\n",
    "step_size_sampling=np.logspace(start=math.log(near_width, base), stop=math.log(far_width, base), num=sampling_num, base=base, dtype=np.uint16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def sliding_window_horizontal(image_strip, step_size, window_width):\n",
    "  # slide a window across the image\n",
    "  for c in np.arange(start=int(window_width/2), stop=image_strip.shape[1]-int(window_width/2), step=step_size, dtype=np.uint16):\n",
    "    yield (c, image_strip[:, int(c-window_width/2):c + int(window_width/2)])\n",
    "\n",
    "def horizontal_strip(image, min_row, height):\n",
    "  return image[min_row-height:min_row, :]\n",
    "\n",
    "def findHotWindows(img, min_row_sampling, max_height_sampling, width_sampling, step_size_sampling, feature_scaler, classifier, return_ims=False):\n",
    "  hot_windows = []\n",
    "  imgs = []\n",
    "  sampling_num = min_row_sampling.shape[0]\n",
    "  for i in range(sampling_num):\n",
    "    strip = horizontal_strip(img, min_row_sampling[i], max_height_sampling[i])\n",
    "    for (c, window) in sliding_window_horizontal(strip, step_size_sampling[i], width_sampling[i]):\n",
    "      resized_window = cv2.resize(window, (64, 64))\n",
    "      features = imagePipeline(resized_window, scaler=feature_scaler)\n",
    "      #scaled_features = feature_scaler.transform(features.reshape(1,-1))\n",
    "      #predict_probs = svc.decision_function(features)\n",
    "      #prediction = (predict_probs-prob_threshold) >= 0\n",
    "      prediction = svc.predict(features)\n",
    "      if prediction == True:\n",
    "        hot_windows.append((c, min_row_sampling[i], max_height_sampling[i], width_sampling[i]))\n",
    "        if return_ims == True:\n",
    "          imgs.append(resized_window)\n",
    "  return hot_windows, imgs\n",
    "\n",
    "def createNominalHeatMap(im, hot_windows):\n",
    "  heatmap = np.zeros_like(im[:,:,0])\n",
    "  plus = max(int(255/len(hot_windows)), 1)\n",
    "  for w in hot_windows:\n",
    "    #w = (center_col, min_row, height, width)\n",
    "    heatmap[int(w[1]-w[2]):int(w[1]), int(w[0]-w[3]/2):int(w[0]+w[3]/2)] += plus\n",
    "  return heatmap\n",
    "\n",
    "im_fname = 'test_images/test1.jpg'\n",
    "test_im = mpimg.imread(im_fname)\n",
    "hot_windows, sub_imgs = findHotWindows(test_im, min_row_sampling, max_height_sampling, width_sampling, step_size_sampling, X_scaler, svc, return_ims=True)\n",
    "\n",
    "for w in hot_windows:\n",
    "  drawBox(test_im, w[0], w[1], w[2], w[3], c=[0, 255, 0])\n",
    "\n",
    "#heatmap = createNominalHeatMap(test_im, hot_windows)\n",
    "\n",
    "f_num = 0\n",
    "f_num = showImage(test_im, f_num)\n",
    "#f_num = showImage(heatmap, f_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extraTrain(imgs, p_folder, n_folder, p_ind=0, n_ind=0):\n",
    "  for img in imgs:\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    while True:\n",
    "      key_press = input()\n",
    "      if key_press is 'p':\n",
    "        cv2.imwrite(p_folder+str(p_ind)+'.jpg', img)\n",
    "        p_ind=p_ind+1\n",
    "        break\n",
    "      elif key_press is 'n':\n",
    "        cv2.imwrite(n_folder+str(n_ind)+'.jpg', img)\n",
    "        n_ind=n_ind+1\n",
    "        break\n",
    "      else:\n",
    "        print(\"Try again\")\n",
    "  return [p_ind, n_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_filenames = glob.glob('test_images/test*.jpg')\n",
    "\n",
    "f_num = 0\n",
    "\n",
    "all_sub_images = []\n",
    "for fname in test_filenames:\n",
    "  im = mpimg.imread(fname)\n",
    "  hot_windows, imgs = findHotWindows(im, min_row_sampling, max_height_sampling, width_sampling, step_size_sampling, X_scaler, svc, return_ims=True)\n",
    "  all_sub_images = all_sub_images+imgs\n",
    "  if hot_windows:\n",
    "    for w in hot_windows:\n",
    "      drawBox(im, w[0], w[1], w[2], w[3], c=[0, int(255*c), 0], thickness = 5)\n",
    "  f_num = showImage(im, f_num, title=fname+' Num. Windows: '+str(len(hot_windows)))\n",
    "\n",
    "  \n",
    "print(len(all_sub_images))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p_folder = 'train_extra/vehicles/'\n",
    "n_folder = 'train_extra/non_vehicles/'\n",
    "p_ind = 0\n",
    "n_ind = 0\n",
    "p_ind, n_ind = extraTrain(all_sub_images, p_folder, n_folder, p_ind, n_ind)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vehicle_filenames = glob.glob('train_images_vehicles/*/*.png')\n",
    "non_vehicle_filenames = glob.glob('train_images_non_vehicles/*/*.png')\n",
    "extra_vehicle_filenames = glob.glob('train_extra/vehicles/*.jpg')\n",
    "extra_non_vehicle_filenames = glob.glob('train_extra/non_vehicles/*.jpg')\n",
    "\n",
    "print(len(extra_vehicle_filenames))\n",
    "print(len(extra_non_vehicle_filenames))\n",
    "\n",
    "train_features_vehicles = extractFeatures(extra_vehicle_filenames)\n",
    "train_features_non_vehicles = extractFeatures(extra_non_vehicle_filenames)\n",
    "\n",
    "vehicle_labels = np.ones((len(train_features_vehicles)))\n",
    "non_vehicle_labels = np.zeros((len(train_features_non_vehicles)))\n",
    "X_data = np.concatenate([train_features_vehicles, train_features_non_vehicles])\n",
    "y_train = np.concatenate([vehicle_labels, non_vehicle_labels])\n",
    "X_scaler = StandardScaler().fit(X_data)\n",
    "X_train = X_scaler.transform(X_data)\n",
    "weights = np.ones_like(y_train)*2.0\n",
    "\n",
    "svc.fit(X_train, y_train, weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# DBSCAN - Density-Based Spatial Clustering of Applications with Noise\n",
    "# scikit-learn documentation: http://scikit-learn.org/stable/modules/clustering.html#dbscan\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# Higher min_samples, stricter classification\n",
    "min_samples = 2\n",
    "# Lower eps, stricter classification\n",
    "eps = 90\n",
    "db = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "\n",
    "def boundingWindow(windows):\n",
    "  if len(windows)==1:\n",
    "    print(\"single window\")\n",
    "    return windows\n",
    "  max_row = np.max(windows[:, 1])\n",
    "  min_row = np.min(windows[:, 1]-windows[:, 2])\n",
    "  max_col = np.max(windows[:, 0]+windows[:, 3]/2)\n",
    "  min_col = np.min(windows[:, 0]-windows[:, 3]/2)\n",
    "  return [int((max_col+min_col)/2),max_row,max_row-min_row,max_col-min_col]\n",
    "  \n",
    "def DBSCANClustering(hot_windows, dbscan_obj, weights=[]):\n",
    "  centers = []\n",
    "  weights=np.array(weights)\n",
    "  for w in hot_windows:\n",
    "    #w = (center_col, min_row, height, width)\n",
    "    centers.append([w[1]-w[2]/2, w[0]])\n",
    "  centers = np.array(centers)\n",
    "  if weights.shape[0]==0:\n",
    "    weights = np.ones(centers.shape[0])\n",
    "  labels = dbscan_obj.fit_predict(centers, sample_weight=weights)\n",
    "  return [labels, centers]\n",
    "\n",
    "test_filenames = glob.glob('test_images/test*.jpg')\n",
    "\n",
    "f_num = 0\n",
    "for fname in test_filenames:\n",
    "  _, only_fname = os.path.split(fname)\n",
    "  im, im_shape = loadImage(fname)\n",
    "  hot_windows, conf = findHotWindows(im, min_row_sampling, max_height_sampling, width_sampling, step_size_sampling, X_scaler, svc)\n",
    "  if hot_windows:\n",
    "    hot_windows = np.array(hot_windows)\n",
    "    labels, centers = DBSCANClustering(hot_windows, db, weights=conf)\n",
    "    #labels, centers = DBSCANClustering(hot_windows, db, weights=[])\n",
    "    num_noise = labels[labels==-1].shape[0]\n",
    "    unique_labels = set(labels)\n",
    "    num_clusters = len(unique_labels) - (1 if -1 in labels else 0)\n",
    "    for l in unique_labels:\n",
    "      masked_windows = hot_windows[(labels == l), :]\n",
    "      if l == -1:\n",
    "        for w in masked_windows:\n",
    "          drawBox(im, w[0], w[1], w[2], w[3], c=[255, 0, 0], thickness = 5)\n",
    "      else:\n",
    "        w = boundingWindow(masked_windows)\n",
    "        drawBox(im, w[0], w[1], w[2], w[3], c=[0, 255, 0], thickness = 5)\n",
    "    f_num = showImage(im, f_num, title=only_fname+' Num. Cars: '+str(num_clusters)+' Num. Noise: '+str(num_noise))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "def pipelineWrapper1(file, im_filepath=False):\n",
    "  global min_row_sampling\n",
    "  global max_height_sampling\n",
    "  global width_sampling\n",
    "  global step_size_sampling\n",
    "  global X_scaler\n",
    "  global svc\n",
    "  \n",
    "  if im_filepath == True:\n",
    "    im = cv2.imread(file)\n",
    "  else:\n",
    "    im = file\n",
    "  \n",
    "  hot_windows, conf = findHotWindows(im, min_row_sampling, max_height_sampling, width_sampling, step_size_sampling, X_scaler, svc)\n",
    "  \n",
    "  for w, c in zip(hot_windows, conf):\n",
    "    drawBox(im, w[0], w[1], w[2], w[3], c=[0, int(255*c), 0], thickness = 5)\n",
    "\n",
    "  return im\n",
    "\n",
    "def pipelineWrapper2(file, im_filepath=False):\n",
    "  global min_row_sampling\n",
    "  global max_height_sampling\n",
    "  global width_sampling\n",
    "  global step_size_sampling\n",
    "  global X_scaler\n",
    "  global svc\n",
    "  global db\n",
    "  \n",
    "  if im_filepath == True:\n",
    "    im = cv2.imread(file)\n",
    "  else:\n",
    "    im = file\n",
    "  hot_windows = findHotWindows(im, min_row_sampling, max_height_sampling, width_sampling, step_size_sampling, X_scaler, svc)\n",
    "  \n",
    "  if hot_windows:\n",
    "    hot_windows = np.array(hot_windows)\n",
    "    labels, centers = DBSCANClustering(hot_windows, db)\n",
    "    unique_labels = set(labels)\n",
    "    for l in unique_labels:\n",
    "      if l == -1: continue\n",
    "      masked_windows = hot_windows[(labels == l), :]\n",
    "      w = boundingWindow(masked_windows)\n",
    "      drawBox(im, w[0], w[1], w[2], w[3], c=[0, c, 0], thickness = 5)\n",
    "    \n",
    "  return im\n",
    "\n",
    "output = 'project_output.mp4'\n",
    "clip1 = VideoFileClip('videos/project_video.mp4')\n",
    "output_clip = clip1.fl_image(pipelineWrapper1)\n",
    "%time output_clip.write_videofile(output, audio=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
